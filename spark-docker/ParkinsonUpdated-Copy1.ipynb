{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the Data and read the column description and ensure you understand each attribute well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "* name - ASCII subject name and recording number\n",
    "* MDVP:Fo(Hz) - Average vocal fundamental frequency\n",
    "* MDVP:Fhi(Hz) - Maximum vocal fundamental frequency\n",
    "* MDVP:Flo(Hz) - Minimum vocal fundamental frequency\n",
    "* MDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several \n",
    "* measures of variation in fundamental frequency\n",
    "* MDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude\n",
    "* NHR,HNR - Two measures of ratio of noise to tonal components in the voice\n",
    "* status - Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
    "* RPDE,D2 - Two nonlinear dynamical complexity measures\n",
    "* DFA - Signal fractal scaling exponent\n",
    "* spread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Parkinson-disease-data-updated\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <td>195.0</td>\n",
       "      <td>154.228641</td>\n",
       "      <td>41.390065</td>\n",
       "      <td>88.333000</td>\n",
       "      <td>117.572000</td>\n",
       "      <td>148.790000</td>\n",
       "      <td>182.769000</td>\n",
       "      <td>260.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <td>195.0</td>\n",
       "      <td>197.104918</td>\n",
       "      <td>91.491548</td>\n",
       "      <td>102.145000</td>\n",
       "      <td>134.862500</td>\n",
       "      <td>175.829000</td>\n",
       "      <td>224.205500</td>\n",
       "      <td>592.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <td>195.0</td>\n",
       "      <td>116.324631</td>\n",
       "      <td>43.521413</td>\n",
       "      <td>65.476000</td>\n",
       "      <td>84.291000</td>\n",
       "      <td>104.315000</td>\n",
       "      <td>140.018500</td>\n",
       "      <td>239.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.033160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.021440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.019580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.064330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>0.119080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.282251</td>\n",
       "      <td>0.194877</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1.302000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shimmer:APQ3</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.015664</td>\n",
       "      <td>0.010153</td>\n",
       "      <td>0.004550</td>\n",
       "      <td>0.008245</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>0.020265</td>\n",
       "      <td>0.056470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shimmer:APQ5</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.017878</td>\n",
       "      <td>0.012024</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.022380</td>\n",
       "      <td>0.079400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDVP:APQ</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.024081</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.007190</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.018260</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.137780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.038360</td>\n",
       "      <td>0.060795</td>\n",
       "      <td>0.169420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHR</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.024847</td>\n",
       "      <td>0.040418</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.314820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HNR</th>\n",
       "      <td>195.0</td>\n",
       "      <td>21.885974</td>\n",
       "      <td>4.425764</td>\n",
       "      <td>8.441000</td>\n",
       "      <td>19.198000</td>\n",
       "      <td>22.085000</td>\n",
       "      <td>25.075500</td>\n",
       "      <td>33.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.431878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPDE</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.498536</td>\n",
       "      <td>0.103942</td>\n",
       "      <td>0.256570</td>\n",
       "      <td>0.421306</td>\n",
       "      <td>0.495954</td>\n",
       "      <td>0.587562</td>\n",
       "      <td>0.685151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFA</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.718099</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>0.574282</td>\n",
       "      <td>0.674758</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>0.761881</td>\n",
       "      <td>0.825288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread1</th>\n",
       "      <td>195.0</td>\n",
       "      <td>-5.684397</td>\n",
       "      <td>1.090208</td>\n",
       "      <td>-7.964984</td>\n",
       "      <td>-6.450096</td>\n",
       "      <td>-5.720868</td>\n",
       "      <td>-5.046192</td>\n",
       "      <td>-2.434031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread2</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.226510</td>\n",
       "      <td>0.083406</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.174351</td>\n",
       "      <td>0.218885</td>\n",
       "      <td>0.279234</td>\n",
       "      <td>0.450493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D2</th>\n",
       "      <td>195.0</td>\n",
       "      <td>2.381826</td>\n",
       "      <td>0.382799</td>\n",
       "      <td>1.423287</td>\n",
       "      <td>2.099125</td>\n",
       "      <td>2.361532</td>\n",
       "      <td>2.636456</td>\n",
       "      <td>3.671155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPE</th>\n",
       "      <td>195.0</td>\n",
       "      <td>0.206552</td>\n",
       "      <td>0.090119</td>\n",
       "      <td>0.044539</td>\n",
       "      <td>0.137451</td>\n",
       "      <td>0.194052</td>\n",
       "      <td>0.252980</td>\n",
       "      <td>0.527367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count        mean        std         min         25%  \\\n",
       "MDVP:Fo(Hz)       195.0  154.228641  41.390065   88.333000  117.572000   \n",
       "MDVP:Fhi(Hz)      195.0  197.104918  91.491548  102.145000  134.862500   \n",
       "MDVP:Flo(Hz)      195.0  116.324631  43.521413   65.476000   84.291000   \n",
       "MDVP:Jitter(%)    195.0    0.006220   0.004848    0.001680    0.003460   \n",
       "MDVP:Jitter(Abs)  195.0    0.000044   0.000035    0.000007    0.000020   \n",
       "MDVP:RAP          195.0    0.003306   0.002968    0.000680    0.001660   \n",
       "MDVP:PPQ          195.0    0.003446   0.002759    0.000920    0.001860   \n",
       "Jitter:DDP        195.0    0.009920   0.008903    0.002040    0.004985   \n",
       "MDVP:Shimmer      195.0    0.029709   0.018857    0.009540    0.016505   \n",
       "MDVP:Shimmer(dB)  195.0    0.282251   0.194877    0.085000    0.148500   \n",
       "Shimmer:APQ3      195.0    0.015664   0.010153    0.004550    0.008245   \n",
       "Shimmer:APQ5      195.0    0.017878   0.012024    0.005700    0.009580   \n",
       "MDVP:APQ          195.0    0.024081   0.016947    0.007190    0.013080   \n",
       "Shimmer:DDA       195.0    0.046993   0.030459    0.013640    0.024735   \n",
       "NHR               195.0    0.024847   0.040418    0.000650    0.005925   \n",
       "HNR               195.0   21.885974   4.425764    8.441000   19.198000   \n",
       "status            195.0    0.753846   0.431878    0.000000    1.000000   \n",
       "RPDE              195.0    0.498536   0.103942    0.256570    0.421306   \n",
       "DFA               195.0    0.718099   0.055336    0.574282    0.674758   \n",
       "spread1           195.0   -5.684397   1.090208   -7.964984   -6.450096   \n",
       "spread2           195.0    0.226510   0.083406    0.006274    0.174351   \n",
       "D2                195.0    2.381826   0.382799    1.423287    2.099125   \n",
       "PPE               195.0    0.206552   0.090119    0.044539    0.137451   \n",
       "\n",
       "                         50%         75%         max  \n",
       "MDVP:Fo(Hz)       148.790000  182.769000  260.105000  \n",
       "MDVP:Fhi(Hz)      175.829000  224.205500  592.030000  \n",
       "MDVP:Flo(Hz)      104.315000  140.018500  239.170000  \n",
       "MDVP:Jitter(%)      0.004940    0.007365    0.033160  \n",
       "MDVP:Jitter(Abs)    0.000030    0.000060    0.000260  \n",
       "MDVP:RAP            0.002500    0.003835    0.021440  \n",
       "MDVP:PPQ            0.002690    0.003955    0.019580  \n",
       "Jitter:DDP          0.007490    0.011505    0.064330  \n",
       "MDVP:Shimmer        0.022970    0.037885    0.119080  \n",
       "MDVP:Shimmer(dB)    0.221000    0.350000    1.302000  \n",
       "Shimmer:APQ3        0.012790    0.020265    0.056470  \n",
       "Shimmer:APQ5        0.013470    0.022380    0.079400  \n",
       "MDVP:APQ            0.018260    0.029400    0.137780  \n",
       "Shimmer:DDA         0.038360    0.060795    0.169420  \n",
       "NHR                 0.011660    0.025640    0.314820  \n",
       "HNR                22.085000   25.075500   33.047000  \n",
       "status              1.000000    1.000000    1.000000  \n",
       "RPDE                0.495954    0.587562    0.685151  \n",
       "DFA                 0.722254    0.761881    0.825288  \n",
       "spread1            -5.720868   -5.046192   -2.434031  \n",
       "spread2             0.218885    0.279234    0.450493  \n",
       "D2                  2.361532    2.636456    3.671155  \n",
       "PPE                 0.194052    0.252980    0.527367  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:, df.columns != 'status'].values[:, 1:]\n",
    "labels = df.loc[:, 'status'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                False\n",
       "MDVP:Fo(Hz)         False\n",
       "MDVP:Fhi(Hz)        False\n",
       "MDVP:Flo(Hz)        False\n",
       "MDVP:Jitter(%)      False\n",
       "MDVP:Jitter(Abs)    False\n",
       "MDVP:RAP            False\n",
       "MDVP:PPQ            False\n",
       "Jitter:DDP          False\n",
       "MDVP:Shimmer        False\n",
       "MDVP:Shimmer(dB)    False\n",
       "Shimmer:APQ3        False\n",
       "Shimmer:APQ5        False\n",
       "MDVP:APQ            False\n",
       "Shimmer:DDA         False\n",
       "NHR                 False\n",
       "HNR                 False\n",
       "status              False\n",
       "RPDE                False\n",
       "DFA                 False\n",
       "spread1             False\n",
       "spread2             False\n",
       "D2                  False\n",
       "PPE                 False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split the data into training and test set in the ratio of 70:30 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA NOT PRE-PROCESSED\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "to_drop = ['status','name']\n",
    "X = df.drop(to_drop, axis=1)\n",
    "y = df['status']\n",
    "X_train, X_test, y_train,  y_test = cross_validation.train_test_split(X, y,train_size=0.7, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATA PRE-PROCESSING\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "\n",
    "\n",
    "to_drop = ['name','status']\n",
    "df1 = df.drop(to_drop, axis=1)\n",
    "\n",
    "Xss = df1.values\n",
    "\n",
    "## Intentional - as scalar is not be applied on the status column. \n",
    "yss = df.status\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaled = scaler.fit_transform(Xss)\n",
    "\n",
    "Xss_train, Xss_test, yss_train, yss_test = cross_validation.train_test_split(Xss, labels, test_size=0.14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification algorithms and compare the models to find the best mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two families of ensemble methods are usually distinguished:\n",
    "\n",
    "In averaging methods, the driving principle is to build several estimators independently and then to average their predictions. On average, the combined estimator is usually better than any of the single base estimator because its variance is reduced.\n",
    "\n",
    "Examples: Bagging methods, Forests of randomized trees, …\n",
    "\n",
    "By contrast, in boosting methods, base estimators are built sequentially and one tries to reduce the bias of the combined estimator. The motivation is to combine several weak models to produce a powerful ensemble.\n",
    "\n",
    "Examples: AdaBoost, Gradient Tree Boosting, …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0]\n",
      "88.13559322033898\n",
      "0.8529411764705882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5,random_state=42)\n",
    "bagging = bagging.fit(X_train, y_train)\n",
    "predictions = bagging.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)*100\n",
    "train_score = bagging.score(X_train, y_train)\n",
    "\n",
    "print (predictions)        \n",
    "print (accuracy)    \n",
    "print (train_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0]\n",
      "89.28571428571429\n",
      "0.8529411764705882\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging_ss = BaggingClassifier(KNeighborsClassifier(),max_samples=0.3, max_features=0.5,random_state=42)\n",
    "bagging_ss = bagging.fit(Xss_train, yss_train)\n",
    "predictions_ss = bagging.predict(Xss_test)\n",
    "accuracy_ss = accuracy_score(yss_test, predictions_ss)*100\n",
    "train_score_ss = bagging.score(Xss_train, yss_train)*100\n",
    "print (predictions)        \n",
    "print (accuracy_ss)    \n",
    "print (train_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0]\n",
      "100.0\n",
      "0.8529411764705882\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=25)\n",
    "clf = clf.fit(Xss, yss)\n",
    "predictions_ss = clf.predict(Xss_test)\n",
    "accuracy_ss = accuracy_score(yss_test, predictions_ss)*100\n",
    "train_score_ss = clf.score(Xss_train, yss_train)*100\n",
    "print (predictions)        \n",
    "print (accuracy_ss)    \n",
    "print (train_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/nDECISION TREE CLASSIFIER\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0]\n",
      "100.0\n",
      "0.8529411764705882\n",
      "0.8561688311688312\n",
      "/n/nRANDOM FOREST CLASSIFIER\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0]\n",
      "100.0\n",
      "0.8529411764705882\n",
      "0.8592592592592592\n",
      "/n/nEXTRA TREE CLASSIFIER\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0]\n",
      "100.0\n",
      "0.8529411764705882\n",
      "0.8592592592592593\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "\n",
    "#CHECK CLF SCORE CALCULATION\n",
    "#####\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "print(\"/n/nDECISION TREE CLASSIFIER\")\n",
    "clf = DecisionTreeClassifier(max_depth=None, min_samples_split=2,random_state=1)\n",
    "clf = clf.fit(Xss, yss)\n",
    "predictions_ss = clf.predict(Xss_test)\n",
    "accuracy_ss = accuracy_score(yss_test, predictions_ss)*100\n",
    "train_score_ss = clf.score(Xss_train, yss_train)*100\n",
    "print (predictions)        \n",
    "print (accuracy_ss)    \n",
    "print (train_score) \n",
    "scores = cross_val_score(clf, Xss_train, yss_train)\n",
    "print (scores.mean())                           \n",
    "\n",
    "\n",
    "print(\"/n/nRANDOM FOREST CLASSIFIER\")\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=1)\n",
    "clf = clf.fit(Xss, yss)\n",
    "predictions_ss = clf.predict(Xss_test)\n",
    "accuracy_ss = accuracy_score(yss_test, predictions_ss)*100\n",
    "train_score_ss = clf.score(Xss_train, yss_train)*100\n",
    "print (predictions)        \n",
    "print (accuracy_ss)    \n",
    "print (train_score) \n",
    "scores = cross_val_score(clf, Xss_test, yss_test)\n",
    "print(scores.mean())                            \n",
    "\n",
    "print(\"/n/nEXTRA TREE CLASSIFIER\")\n",
    "clf = ExtraTreesClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=1)\n",
    "clf = clf.fit(Xss, yss)\n",
    "predictions_ss = clf.predict(Xss_test)\n",
    "accuracy_ss = accuracy_score(yss_test, predictions_ss)*100\n",
    "train_score_ss = clf.score(Xss_train, yss_train)*100\n",
    "print (predictions)        \n",
    "print (accuracy_ss)    \n",
    "print (train_score) \n",
    "scores = cross_val_score(clf, Xss_test, yss_test)\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.67 (+/- 0.07) [Logistic Regression]\n",
      "Accuracy: 86.67 (+/- 0.12) [Random Forest]\n",
      "Accuracy: 90.00 (+/- 0.08) [Naive Bayes]\n",
      "Accuracy: 90.00 (+/- 0.08) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, Xss_test, yss_test, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean()*100, scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training classifiers\n",
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3)], voting='soft', weights=[2,1,2])\n",
    "\n",
    "clf1 = clf1.fit(Xss_train,yss_train)\n",
    "clf2 = clf2.fit(Xss_train,yss_train)\n",
    "clf3 = clf3.fit(Xss_train,yss_train)\n",
    "eclf = eclf.fit(Xss_train,yss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n",
    "\n",
    "params = {'lr__C': [1.0, 100.0], 'rf__n_estimators': [20, 200],}\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "grid = grid.fit(Xss_train, yss_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.67 (+/- 0.07) [Logistic Regression]\n",
      "Accuracy: 86.67 (+/- 0.12) [Random Forest]\n",
      "Accuracy: 90.00 (+/- 0.08) [Naive Bayes]\n",
      "Accuracy: 90.00 (+/- 0.08) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft')\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, Xss_test, yss_test, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean()*100, scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.67 (+/- 0.07) [Logistic Regression]\n",
      "Accuracy: 86.67 (+/- 0.12) [Random Forest]\n",
      "Accuracy: 90.00 (+/- 0.08) [Naive Bayes]\n",
      "Accuracy: 86.67 (+/- 0.07) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[2,5,1])\n",
    "\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, Xss_test, yss_test, cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean()*100, scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8683982683982684"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, Xss_train, yss_train)\n",
    "scores.mean()                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
